{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpontaneousActivity.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2ikBxHnQ6BkboxdwqvkAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonialouise/ts_class/blob/main/notebooks/SpontaneousActivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spontaneous Neuronal Activity Classifier\n",
        "This notebook allows users to run a pretrained model on their own data to identify neurons exhibiting spontaneous activity. Furthermore, users can fine-tune this model using their own data."
      ],
      "metadata": {
        "id": "5NBXm8AJgCWs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhuybhzUW_2s",
        "outputId": "da8f90ca-5ef3-473f-fec0-5299e325c521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ts_class' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#@markdown The Github repository with all custom functions, the model training datasets and the pretrained models are copied to the environment of this notebook. This will take a couple of seconds.\n",
        "\n",
        "#@markdown *Note: You can check the code underlying each cell by double-clicking on it.*\n",
        "\n",
        "import os\n",
        "\n",
        "# If in Colab and not yet downloaded, download GitHub repository and change working directory\n",
        "if os.getcwd() == '/content':  \n",
        "    !git clone https://github.com/sonialouise/ts_class.git\n",
        "    os.chdir('ts_class')\n",
        "    \n",
        "# If executed as jupyter notebook on own computer, change to parent directory for imports\n",
        "if os.path.basename( os.getcwd() ) == 'activity_classifier':\n",
        "    %cd ..\n",
        "    print('New working directory:', os.getcwd() )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull "
      ],
      "metadata": {
        "id": "XQ4sR3lETWhh",
        "outputId": "3c03bef2-20fb-446b-c311-3932e7dbada8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/sonialouise/ts_class\n",
            "   6514133..69ebaed  main       -> origin/main\n",
            "Updating 6514133..69ebaed\n",
            "Fast-forward\n",
            " activity_classifier/prepare_data.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download packages required to run the model\n",
        "\n",
        "%%capture\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# python imports\n",
        "import pickle\n",
        "import argparse\n",
        "import logging\n",
        "import pandas as pd\n",
        "\n",
        "# ts_class packages, imported from the downloaded Github repository\n",
        "from activity_classifier.main import run_model\n",
        "from activity_classifier.config import TSF_MODEL, RISE_MODEL, OBS, PREDICTION, OUTPUT_PATH\n",
        "from activity_classifier.prepare_data import prepare_data\n",
        "from activity_classifier.retrain_models import retrain_tsf, retrain_rise\n",
        "\n",
        "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)"
      ],
      "metadata": {
        "id": "VXUzCxoQYm52"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mu91Rb6WDLix"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown If you are testing the script, leave the below two fields unchanged. If you want to apply the model to your own data, you need to upload your data first. \n",
        "\n",
        "#@markdown To upload data, click on the **folder symbol (\"Files\")** on the left side of the Colaboratory notebook, and select 'Upload to session storage'. Next, indicate the file path of the uploaded file in the variable **`file_path`** below. Finally, indicate the total duration in seconds (decimal) of your recordings in the variable **`duration`**, and the required sampling rate (frames per second) in the variable **`sampling_rate`**..\n",
        "\n",
        "#@markdown Note that for data longer than 550 frames, only the first 550 frames will be used for the prediction, unless the model is retrained with the higher frame count.\n",
        "\n",
        "file_path = \"data/test_set.csv\" #@param {type:\"string\"}\n",
        "\n",
        "duration = 137.5 #@param {type:\"number\"}  \n",
        "\n",
        "sampling_rate = 4 #@param {type: \"number\"}"
      ],
      "metadata": {
        "id": "FhLlOA3uawQQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Play this cell to retrain the model. If this is not required, skip this cell.<br />\n",
        "#@markdown Note that training data should contain the following:<br />\n",
        "#@markdown - Rows containing individual cell recordings, with columns indicating timepoints\n",
        "#@markdown - Numbered column headers (starting at zero) to indicate the captured timepoints\n",
        "#@markdown - A 'status' column to the right of recordings, containing 'active' or 'inactive' labels for each row <br />\n",
        "\n",
        "#@markdown Ensure that data file path and frame count have been updated in the above cell.\n",
        "    \n",
        "logging.info(\"1. Reading csv file...\")\n",
        "data = pd.read_csv('data/training_data.csv', header=0)\n",
        "logging.info(\"2. Normalising data...\")\n",
        "total_frames = int(duration * sampling_rate)\n",
        "trace_data = data.iloc[:, 0:total_frames]\n",
        "data = pd.concat([prepare_data(trace_data, duration, sampling_rate), data['status']], axis=1)\n",
        "logging.info(\"3. Retraining Time Series Classifier...\")\n",
        "retrain_tsf(data)\n",
        "logging.info(\"4. Retraining Random Interval Spectral Ensemble...\")\n",
        "retrain_rise(data)\n",
        "logging.info(\"5. Retraining Complete\")"
      ],
      "metadata": {
        "id": "gfRMRaZwadBP",
        "outputId": "c67e7732-2822-4d81-c95e-b5874df9419f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS TSF: {'ACCURACY': 0.9105495598256852, 'PRECISION': 0.8283819604233779, 'RECALL': 0.7232455632945328}\n",
            "RESULTS RISE: {'ACCURACY': 0.9701792869468573, 'PRECISION': 0.9484897860759929, 'RECALL': 0.9023335231146226}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Play this cell to run the model on your data. The model predictions can be found in the \"Files\" folder under ts_class -> data.\n",
        "\n",
        "logging.info(\"1. Reading csv file...\")\n",
        "data = pd.read_csv(file_path, header=0)\n",
        "logging.info(\"2. Normalising data...\")\n",
        "total_frames = int(duration * sampling_rate)\n",
        "trace_data = data.iloc[:, 0:total_frames]\n",
        "data = prepare_data(trace_data, duration, sampling_rate)\n",
        "logging.info(\"3. Predicting with TimeSeries Forest Classifier...\")\n",
        "data = run_model(data, TSF_MODEL, 'TSF')\n",
        "logging.info(\"4. Predicting with Random Interval Spectral Ensemble...\")\n",
        "data = run_model(data, RISE_MODEL, 'RISE')\n",
        "logging.info(\"5. Saving output...\")\n",
        "data.to_csv(OUTPUT_PATH)\n",
        "logging.info(\"6. Process complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXlGDNhFdNOy",
        "outputId": "8ed67822-f859-4b2c-b921-b750ff3a177e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ts_class/activity_classifier/prepare_data.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[OBS] = [interpolate_data(row, seconds, end_frame_rate) for row in np.array(data)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvCHo2LdfDwM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}